# 数据结构

## 字典

```c
typedef struct dict {
  // 泛型方法集合
  dictType *type;
  // 私有数据
  void *privdata;
  // hash表
  dictht ht[2];
  // rehash标记
  int rehashidx;
} dict;
```

这里主要的是关于字典管理的顶层封装

| field         | description                                                |
| ------------- | ---------------------------------------------------------- |
| ``rehashidx`` | ``rehash``时候的进度<br />默认或者``hash``完成，保持``-1`` |
| ``ht[2]``     | 具体存储数据的哈希表<br />主备做``rehash``切换             |
| ``type``      | 泛型方法集合                                               |
| ``prividata`` | 泛型方法参数                                               |

> 这里主要说明泛型支持的``type``和``privdata``，其他参数后续说明。
>
> ## ``dictType``
>
> ```c
> typedef struct dictType{
>   // 计算hash值
>   unsigned int (*hashFunction) (const *void key);
>   // 复制key
>   void *(*keyDup) (void *prividata, const void *key);
>   // 复制值
>   void *(*valDup) (void *prividata, const void *obj);
>   // key比较
>   int (*keyCompare) (void *prividata, const void *key1, const void *key2);
>   // key销毁
>   void (*keyDestructor) (void *prividata, void *key);
>   // 值销毁
>   void (*valDestructir) (void *privdata, void *obj);
> } dictType;
> ```
>
> 泛型方法供后续调用，替换内容，流程不变。

## 哈希表

```c
typedef struct dictht{
  // hash节点数组
  dictEntry **table;
  // hash表大小
  unsigned long size;
  // 掩码，size为 2^n 的时候，a % n = a & (n - 1)
  unsigned long sizemask;
  // 节点数量，存在hash冲突，因此数组长度和节点个数并不严格一致
  unsigned long used;
} dictht;
```

## 哈希节点

```c
typedef struct dictEntry{
  void *key;
  union{
    void *val;
    uint64_tu64;
    int64_ts64;
  } v;
  // 下一个值，贯穿成为链表
  struct dictEntry *next;
} dictEntry;
```

``redis``使用<font color='red'>链地址法</font>解决``hash``冲突问题，具体办法见后。

# 哈希算法

## 元素哈希

```c
// 使用设置的hash算法计算元素hash
hash = dict->type->hashFunction(key);
```

``Redis``中使用的哈希算法为[MurmurHash2](http://code.google.com/p/smhasher)，现已更新到``MurmurHash3``

## 数组映射

```c
// hash % size; 讲hash映射到数组区间，确定存放位置
index = hash & dict.ht[x].sizemask
```

## 冲突解决

不论是``hash``算法的冲突还是数组的有限长度，最后都会面临一个数组多个节点的情况。

这里使用<font color='red'>链地址法</font>进行解决，也就是前面需要``*next``的原因，每一个节点都是一个链表，允许存储多个元素。

# Rehash

## 执行条件

```c
// 负载因子 = 元素个数 / 数组长度
load_factor = ht[0].used / ht[0].size;
```

| condition                                         | operation |
| ------------------------------------------------- | --------- |
| ``load_factory < 0.1``                            | 缩容      |
| ``!(BGSAVE || BGREWRITEAOF) && load_factor >= 1`` | 扩容      |
| ``(BGSAVE || BGREWRITEAOF)  && load_factor >= 5`` | 扩容      |

<font color='red'>因为大多数操作系统都会使用``copy-on-write``来优化子进程执行效率，因此在执行``BGSAVE``或``BGREWRITEAOF``的时候提高负载因子阈值。</font>

<font color='red'>尽可能的在子进程执行期间降低扩展操作，避免不必要的内存写入，最小限度的节约内存。</font>

## 执行过程

==1. 空间分配==

原始空间使用的都是``ht[0]``，确定操作以后，首先对``ht[1]``进行空间申请，具体大小如下

| operation | size                                                   |
| --------- | ------------------------------------------------------ |
| 扩容      | $2 \times \text{ht}[0].\text{used}$                    |
| 缩容      | $\lceil 2^n |(2^n \ge \text{ht}[0].\text{used})\rceil$ |

==2. 数据迁移==

然后就开始讲``htt[0]``里面的数据，逐个的往``ht[1]``中迁移，相当于重新进行插入操作。这也是为什么叫做``rehash``。

每完成一格元素的迁移，``rehashidx += 1``，当``rehashidx = sizemask``的时候，数据迁移完毕。

==3. 结构复位==

当数据迁移完毕以后，此时``ht[0]``中没有任何数据，全部数据位于``ht[1]``，且容量成为了预先计算的值。

此时的``ht[0]``可以直接进行回收，并将``ht[1]``通过指针移交给``ht[0]``，这就是``**table``指针的好处所在。

同时，``rehashidx = -1``，一切恢复原样。

## 中间操作

迁移操作过程中，外部可能还会进行一些操作

- 读

  迁移过程中，数据分布在两个地方，优先查找``ht[0]``，如果没找到就查找``ht[1]``

- 写

  迁移过程中始终往``ht[1]``中进行写入，确保``ht[0]``中元素单调递减。

# ``字典のAPI``

| method               | description        | O      |
| -------------------- | ------------------ | ------ |
| ``dictCreate``       | 创建一个字典       | $O(1)$ |
| ``dictAdd``          | 添加``k-v``        | $O(1)$ |
| ``dictReplace``      | 替换``k-v``        | $O(1)$ |
| ``dictFetchValue``   | ``get(k)``         | $O(1)$ |
| ``dictGetRandomKey`` | 返回元素随机``k``  | $O(1)$ |
| ``dictDelete``       | ``del(k)``         | $O(1)$ |
| ``dictRelease``      | 释放字典以及子元素 | $O(N)$ |

